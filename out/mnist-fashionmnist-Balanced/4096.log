ic| len(dset): 60000
Run name: mnist-fashionmnist-Balanced-4096
  0%|          | 0/60000 [00:00<?, ?it/s]  1%|          | 664/60000 [00:00<00:08, 6637.43it/s]  2%|▏         | 1344/60000 [00:00<00:08, 6728.88it/s]  3%|▎         | 2017/60000 [00:00<00:08, 6547.66it/s]  4%|▍         | 2673/60000 [00:00<00:08, 6443.99it/s]  6%|▌         | 3318/60000 [00:00<00:08, 6380.25it/s]  7%|▋         | 3957/60000 [00:00<00:08, 6318.86it/s]  8%|▊         | 4590/60000 [00:00<00:08, 6297.87it/s]  9%|▊         | 5220/60000 [00:00<00:08, 6277.03it/s] 10%|▉         | 5849/60000 [00:00<00:08, 6280.45it/s] 11%|█         | 6480/60000 [00:01<00:08, 6287.61it/s] 12%|█▏        | 7110/60000 [00:01<00:08, 6289.84it/s] 13%|█▎        | 7740/60000 [00:01<00:08, 6256.25it/s] 14%|█▍        | 8371/60000 [00:01<00:08, 6271.87it/s] 15%|█▍        | 8999/60000 [00:01<00:08, 6265.06it/s] 16%|█▌        | 9629/60000 [00:01<00:08, 6274.88it/s] 17%|█▋        | 10260/60000 [00:01<00:07, 6285.12it/s] 18%|█▊        | 10891/60000 [00:01<00:07, 6291.56it/s] 19%|█▉        | 11521/60000 [00:01<00:07, 6293.66it/s] 20%|██        | 12151/60000 [00:01<00:07, 6294.13it/s] 21%|██▏       | 12782/60000 [00:02<00:07, 6296.70it/s] 22%|██▏       | 13412/60000 [00:02<00:07, 6296.31it/s] 23%|██▎       | 14042/60000 [00:02<00:07, 6293.89it/s] 24%|██▍       | 14672/60000 [00:02<00:07, 6293.13it/s] 26%|██▌       | 15303/60000 [00:02<00:07, 6295.86it/s] 27%|██▋       | 15933/60000 [00:02<00:06, 6296.78it/s] 28%|██▊       | 16563/60000 [00:02<00:06, 6293.71it/s] 29%|██▊       | 17193/60000 [00:02<00:06, 6275.85it/s] 30%|██▉       | 17824/60000 [00:02<00:06, 6284.35it/s] 31%|███       | 18453/60000 [00:02<00:06, 6285.25it/s] 32%|███▏      | 19083/60000 [00:03<00:06, 6289.12it/s] 33%|███▎      | 19713/60000 [00:03<00:06, 6291.96it/s] 34%|███▍      | 20343/60000 [00:03<00:06, 6292.46it/s] 35%|███▍      | 20973/60000 [00:03<00:06, 6269.65it/s] 36%|███▌      | 21603/60000 [00:03<00:06, 6278.44it/s] 37%|███▋      | 22233/60000 [00:03<00:06, 6283.46it/s] 38%|███▊      | 22862/60000 [00:03<00:05, 6283.23it/s] 39%|███▉      | 23491/60000 [00:03<00:05, 6284.02it/s] 40%|████      | 24120/60000 [00:03<00:05, 6262.38it/s] 41%|████      | 24747/60000 [00:03<00:05, 6246.18it/s] 42%|████▏     | 25372/60000 [00:04<00:05, 6240.49it/s] 43%|████▎     | 26002/60000 [00:04<00:05, 6257.50it/s] 44%|████▍     | 26632/60000 [00:04<00:05, 6267.55it/s] 45%|████▌     | 27262/60000 [00:04<00:05, 6276.93it/s] 46%|████▋     | 27892/60000 [00:04<00:05, 6281.97it/s] 48%|████▊     | 28523/60000 [00:04<00:05, 6288.59it/s] 49%|████▊     | 29154/60000 [00:04<00:04, 6294.42it/s] 50%|████▉     | 29785/60000 [00:04<00:04, 6296.80it/s] 51%|█████     | 30417/60000 [00:04<00:04, 6300.67it/s] 52%|█████▏    | 31049/60000 [00:04<00:04, 6304.72it/s] 53%|█████▎    | 31680/60000 [00:05<00:04, 6303.30it/s] 54%|█████▍    | 32311/60000 [00:05<00:04, 6298.44it/s] 55%|█████▍    | 32941/60000 [00:05<00:04, 6294.67it/s] 56%|█████▌    | 33571/60000 [00:05<00:04, 6253.09it/s] 57%|█████▋    | 34200/60000 [00:05<00:04, 6261.24it/s] 58%|█████▊    | 34828/60000 [00:05<00:04, 6265.39it/s] 59%|█████▉    | 35456/60000 [00:05<00:03, 6268.09it/s] 60%|██████    | 36084/60000 [00:05<00:03, 6270.71it/s] 61%|██████    | 36713/60000 [00:05<00:03, 6276.14it/s] 62%|██████▏   | 37345/60000 [00:05<00:03, 6287.21it/s] 63%|██████▎   | 37977/60000 [00:06<00:03, 6295.83it/s] 64%|██████▍   | 38609/60000 [00:06<00:03, 6301.52it/s] 65%|██████▌   | 39240/60000 [00:06<00:03, 6302.47it/s] 66%|██████▋   | 39871/60000 [00:06<00:03, 6274.00it/s] 67%|██████▋   | 40499/60000 [00:06<00:03, 6266.52it/s] 69%|██████▊   | 41126/60000 [00:06<00:03, 6264.03it/s] 70%|██████▉   | 41753/60000 [00:06<00:02, 6253.14it/s] 71%|███████   | 42383/60000 [00:06<00:02, 6265.25it/s] 72%|███████▏  | 43014/60000 [00:06<00:02, 6276.21it/s] 73%|███████▎  | 43644/60000 [00:06<00:02, 6282.72it/s] 74%|███████▍  | 44274/60000 [00:07<00:02, 6287.53it/s] 75%|███████▍  | 44906/60000 [00:07<00:02, 6294.90it/s] 76%|███████▌  | 45536/60000 [00:07<00:02, 6294.50it/s] 77%|███████▋  | 46166/60000 [00:07<00:02, 6266.43it/s] 78%|███████▊  | 46797/60000 [00:07<00:02, 6277.27it/s] 79%|███████▉  | 47427/60000 [00:07<00:02, 6282.90it/s] 80%|████████  | 48056/60000 [00:07<00:01, 6270.72it/s] 81%|████████  | 48684/60000 [00:07<00:01, 6249.36it/s] 82%|████████▏ | 49309/60000 [00:07<00:01, 6240.12it/s] 83%|████████▎ | 49934/60000 [00:07<00:01, 6213.54it/s] 84%|████████▍ | 50556/60000 [00:08<00:01, 6213.45it/s] 85%|████████▌ | 51179/60000 [00:08<00:01, 6215.82it/s] 86%|████████▋ | 51801/60000 [00:08<00:01, 6216.53it/s] 87%|████████▋ | 52432/60000 [00:08<00:01, 6241.52it/s] 88%|████████▊ | 53064/60000 [00:08<00:01, 6263.71it/s] 89%|████████▉ | 53696/60000 [00:08<00:01, 6277.78it/s] 91%|█████████ | 54328/60000 [00:08<00:00, 6289.24it/s] 92%|█████████▏| 54959/60000 [00:08<00:00, 6294.39it/s] 93%|█████████▎| 55590/60000 [00:08<00:00, 6298.44it/s] 94%|█████████▎| 56222/60000 [00:08<00:00, 6303.57it/s] 95%|█████████▍| 56854/60000 [00:09<00:00, 6306.19it/s] 96%|█████████▌| 57486/60000 [00:09<00:00, 6309.76it/s] 97%|█████████▋| 58117/60000 [00:09<00:00, 6290.51it/s] 98%|█████████▊| 58748/60000 [00:09<00:00, 6296.14it/s] 99%|█████████▉| 59378/60000 [00:09<00:00, 6271.75it/s]100%|██████████| 60000/60000 [00:09<00:00, 6285.50it/s]
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 367921.40it/s]
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
MNIST-FashionMNIST InD train dataset loaded with 60000 samples.
torch.Size([40960, 3, 32, 32])
Out-of-distribution dataset size: 40960
Validation set size: 10000
Starting Training Loop...
[0/20][0/211]	Loss_D: 1.3949	Loss_G: 0.6926	D(x): 0.4978	D(x_out): 0.5215	D(G(z)): 0.4799 / 0.5003
[0/20][50/211]	Loss_D: 0.8078	Loss_G: 0.8139	D(x): 0.7269	D(x_out): 0.4022	D(G(z)): 0.3677 / 0.4433
[0/20][100/211]	Loss_D: 0.7004	Loss_G: 1.0621	D(x): 0.7752	D(x_out): 0.3652	D(G(z)): 0.3520 / 0.3459
[0/20][150/211]	Loss_D: 0.6265	Loss_G: 1.1117	D(x): 0.8084	D(x_out): 0.3413	D(G(z)): 0.3344 / 0.3291
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
0.99999853515625
checkpoint!
[1/20][0/211]	Loss_D: 0.6139	Loss_G: 1.1167	D(x): 0.8142	D(x_out): 0.3391	D(G(z)): 0.3291 / 0.3275
[1/20][50/211]	Loss_D: 0.5529	Loss_G: 1.1751	D(x): 0.8411	D(x_out): 0.3175	D(G(z)): 0.3130 / 0.3089
[1/20][100/211]	Loss_D: 0.5041	Loss_G: 1.2254	D(x): 0.8617	D(x_out): 0.3006	D(G(z)): 0.2958 / 0.2938
[1/20][150/211]	Loss_D: 0.4600	Loss_G: 1.2816	D(x): 0.8798	D(x_out): 0.2841	D(G(z)): 0.2798 / 0.2777
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
0.9999998914930555
checkpoint!
[2/20][0/211]	Loss_D: 0.4519	Loss_G: 1.2886	D(x): 0.8831	D(x_out): 0.2826	D(G(z)): 0.2750 / 0.2758
[2/20][50/211]	Loss_D: 0.4145	Loss_G: 1.3421	D(x): 0.8982	D(x_out): 0.2650	D(G(z)): 0.2626 / 0.2614
[2/20][100/211]	Loss_D: 0.3814	Loss_G: 1.3964	D(x): 0.9105	D(x_out): 0.2548	D(G(z)): 0.2443 / 0.2476
[2/20][150/211]	Loss_D: 0.3523	Loss_G: 1.4618	D(x): 0.9208	D(x_out): 0.2355	D(G(z)): 0.2367 / 0.2319
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
1.0
checkpoint!
[3/20][0/211]	Loss_D: 0.3463	Loss_G: 1.4642	D(x): 0.9228	D(x_out): 0.2335	D(G(z)): 0.2331 / 0.2314
[3/20][50/211]	Loss_D: 0.3211	Loss_G: 1.5183	D(x): 0.9314	D(x_out): 0.2213	D(G(z)): 0.2206 / 0.2192
[3/20][100/211]	Loss_D: 0.2977	Loss_G: 1.5735	D(x): 0.9391	D(x_out): 0.2103	D(G(z)): 0.2078 / 0.2074
[3/20][150/211]	Loss_D: 0.2791	Loss_G: 1.6177	D(x): 0.9450	D(x_out): 0.2013	D(G(z)): 0.1960 / 0.1984
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
1.0
[4/20][0/211]	Loss_D: 0.2726	Loss_G: 1.6205	D(x): 0.9467	D(x_out): 0.2007	D(G(z)): 0.1904 / 0.1979
[4/20][50/211]	Loss_D: 0.2561	Loss_G: 1.6994	D(x): 0.9513	D(x_out): 0.1860	D(G(z)): 0.1853 / 0.1829
[4/20][100/211]	Loss_D: 0.2383	Loss_G: 1.7384	D(x): 0.9564	D(x_out): 0.1769	D(G(z)): 0.1746 / 0.1759
[4/20][150/211]	Loss_D: 0.2219	Loss_G: 1.7995	D(x): 0.9605	D(x_out): 0.1675	D(G(z)): 0.1643 / 0.1654
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
1.0
[5/20][0/211]	Loss_D: 0.2205	Loss_G: 1.8190	D(x): 0.9610	D(x_out): 0.1676	D(G(z)): 0.1618 / 0.1623
[5/20][50/211]	Loss_D: 0.2055	Loss_G: 1.8562	D(x): 0.9648	D(x_out): 0.1542	D(G(z)): 0.1575 / 0.1563
[5/20][100/211]	Loss_D: 0.1927	Loss_G: 1.9279	D(x): 0.9681	D(x_out): 0.1499	D(G(z)): 0.1454 / 0.1455
[5/20][150/211]	Loss_D: 0.1824	Loss_G: 1.9271	D(x): 0.9707	D(x_out): 0.1422	D(G(z)): 0.1388 / 0.1456
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
1.0
[6/20][0/211]	Loss_D: 0.1787	Loss_G: 1.9859	D(x): 0.9706	D(x_out): 0.1386	D(G(z)): 0.1377 / 0.1373
[6/20][50/211]	Loss_D: 0.1676	Loss_G: 2.0515	D(x): 0.9734	D(x_out): 0.1300	D(G(z)): 0.1322 / 0.1286
[6/20][100/211]	Loss_D: 0.1572	Loss_G: 2.1190	D(x): 0.9756	D(x_out): 0.1208	D(G(z)): 0.1274 / 0.1202
[6/20][150/211]	Loss_D: 0.1480	Loss_G: 2.1689	D(x): 0.9775	D(x_out): 0.1151	D(G(z)): 0.1202 / 0.1144
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
1.0
[7/20][0/211]	Loss_D: 0.1460	Loss_G: 2.1586	D(x): 0.9779	D(x_out): 0.1143	D(G(z)): 0.1184 / 0.1155
[7/20][50/211]	Loss_D: 0.1377	Loss_G: 2.2031	D(x): 0.9796	D(x_out): 0.1105	D(G(z)): 0.1103 / 0.1105
[7/20][100/211]	Loss_D: 0.1317	Loss_G: 2.2450	D(x): 0.9809	D(x_out): 0.1092	D(G(z)): 0.1022 / 0.1060
[7/20][150/211]	Loss_D: 0.1226	Loss_G: 2.3142	D(x): 0.9824	D(x_out): 0.1006	D(G(z)): 0.0984 / 0.0989
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
1.0
[8/20][0/211]	Loss_D: 0.1220	Loss_G: 2.3229	D(x): 0.9821	D(x_out): 0.0982	D(G(z)): 0.0991 / 0.0980
[8/20][50/211]	Loss_D: 0.1146	Loss_G: 2.3755	D(x): 0.9839	D(x_out): 0.0951	D(G(z)): 0.0921 / 0.0930
[8/20][100/211]	Loss_D: 0.1093	Loss_G: 2.4321	D(x): 0.9847	D(x_out): 0.0911	D(G(z)): 0.0878 / 0.0879
[8/20][150/211]	Loss_D: 0.1027	Loss_G: 2.4683	D(x): 0.9859	D(x_out): 0.0856	D(G(z)): 0.0837 / 0.0848
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
1.0
[9/20][0/211]	Loss_D: 0.1018	Loss_G: 2.4949	D(x): 0.9860	D(x_out): 0.0832	D(G(z)): 0.0847 / 0.0825
[9/20][50/211]	Loss_D: 0.0965	Loss_G: 2.5726	D(x): 0.9868	D(x_out): 0.0797	D(G(z)): 0.0800 / 0.0764
[9/20][100/211]	Loss_D: 0.0913	Loss_G: 2.6093	D(x): 0.9877	D(x_out): 0.0776	D(G(z)): 0.0742 / 0.0736
[9/20][150/211]	Loss_D: 0.0866	Loss_G: 2.6171	D(x): 0.9885	D(x_out): 0.0714	D(G(z)): 0.0731 / 0.0731
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
1.0
[10/20][0/211]	Loss_D: 0.0856	Loss_G: 2.6533	D(x): 0.9887	D(x_out): 0.0706	D(G(z)): 0.0723 / 0.0704
[10/20][50/211]	Loss_D: 0.0814	Loss_G: 2.6803	D(x): 0.9893	D(x_out): 0.0678	D(G(z)): 0.0687 / 0.0686
[10/20][100/211]	Loss_D: 0.0772	Loss_G: 2.7483	D(x): 0.9899	D(x_out): 0.0645	D(G(z)): 0.0653 / 0.0641
[10/20][150/211]	Loss_D: 0.0754	Loss_G: 2.7462	D(x): 0.9904	D(x_out): 0.0657	D(G(z)): 0.0601 / 0.0642
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
1.0
[11/20][0/211]	Loss_D: 0.0728	Loss_G: 2.7837	D(x): 0.9906	D(x_out): 0.0611	D(G(z)): 0.0616 / 0.0618
[11/20][50/211]	Loss_D: 0.0692	Loss_G: 2.8358	D(x): 0.9911	D(x_out): 0.0590	D(G(z)): 0.0580 / 0.0587
[11/20][100/211]	Loss_D: 0.0660	Loss_G: 2.8628	D(x): 0.9915	D(x_out): 0.0554	D(G(z)): 0.0564 / 0.0571
[11/20][150/211]	Loss_D: 0.0628	Loss_G: 2.9331	D(x): 0.9920	D(x_out): 0.0535	D(G(z)): 0.0532 / 0.0533
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
1.0
[12/20][0/211]	Loss_D: 0.0622	Loss_G: 2.9445	D(x): 0.9921	D(x_out): 0.0532	D(G(z)): 0.0524 / 0.0527
[12/20][50/211]	Loss_D: 0.0593	Loss_G: 2.9896	D(x): 0.9925	D(x_out): 0.0508	D(G(z)): 0.0501 / 0.0503
[12/20][100/211]	Loss_D: 0.0566	Loss_G: 2.9972	D(x): 0.9929	D(x_out): 0.0500	D(G(z)): 0.0465 / 0.0499
[12/20][150/211]	Loss_D: 0.0542	Loss_G: 3.0778	D(x): 0.9932	D(x_out): 0.0467	D(G(z)): 0.0458 / 0.0461
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
1.0
[13/20][0/211]	Loss_D: 0.0536	Loss_G: 3.1053	D(x): 0.9932	D(x_out): 0.0459	D(G(z)): 0.0456 / 0.0448
[13/20][50/211]	Loss_D: 0.0511	Loss_G: 3.1140	D(x): 0.9936	D(x_out): 0.0442	D(G(z)): 0.0433 / 0.0444
[13/20][100/211]	Loss_D: 0.0491	Loss_G: 3.1490	D(x): 0.9939	D(x_out): 0.0426	D(G(z)): 0.0414 / 0.0429
[13/20][150/211]	Loss_D: 0.0466	Loss_G: 3.2234	D(x): 0.9942	D(x_out): 0.0397	D(G(z)): 0.0404 / 0.0399
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
1.0
[14/20][0/211]	Loss_D: 0.0463	Loss_G: 3.2174	D(x): 0.9943	D(x_out): 0.0402	D(G(z)): 0.0392 / 0.0401
[14/20][50/211]	Loss_D: 0.0442	Loss_G: 3.2726	D(x): 0.9945	D(x_out): 0.0380	D(G(z)): 0.0380 / 0.0379
[14/20][100/211]	Loss_D: 0.0423	Loss_G: 3.3113	D(x): 0.9948	D(x_out): 0.0367	D(G(z)): 0.0360 / 0.0365
[14/20][150/211]	Loss_D: 0.0406	Loss_G: 3.3794	D(x): 0.9950	D(x_out): 0.0345	D(G(z)): 0.0353 / 0.0341
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
1.0
[15/20][0/211]	Loss_D: 0.0402	Loss_G: 3.3696	D(x): 0.9950	D(x_out): 0.0342	D(G(z)): 0.0350 / 0.0344
[15/20][50/211]	Loss_D: 0.0384	Loss_G: 3.4048	D(x): 0.9953	D(x_out): 0.0336	D(G(z)): 0.0327 / 0.0332
[15/20][100/211]	Loss_D: 0.0369	Loss_G: 3.4708	D(x): 0.9954	D(x_out): 0.0321	D(G(z)): 0.0315 / 0.0311
[15/20][150/211]	Loss_D: 0.0353	Loss_G: 3.4588	D(x): 0.9957	D(x_out): 0.0311	D(G(z)): 0.0300 / 0.0315
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
1.0
[16/20][0/211]	Loss_D: 0.0351	Loss_G: 3.4547	D(x): 0.9957	D(x_out): 0.0304	D(G(z)): 0.0301 / 0.0316
[16/20][50/211]	Loss_D: 0.0336	Loss_G: 3.5583	D(x): 0.9959	D(x_out): 0.0284	D(G(z)): 0.0296 / 0.0285
[16/20][100/211]	Loss_D: 0.0322	Loss_G: 3.5820	D(x): 0.9961	D(x_out): 0.0287	D(G(z)): 0.0271 / 0.0278
[16/20][150/211]	Loss_D: 0.0309	Loss_G: 3.6042	D(x): 0.9962	D(x_out): 0.0270	D(G(z)): 0.0265 / 0.0272
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
1.0
[17/20][0/211]	Loss_D: 0.0306	Loss_G: 3.6295	D(x): 0.9963	D(x_out): 0.0258	D(G(z)): 0.0273 / 0.0265
[17/20][50/211]	Loss_D: 0.0294	Loss_G: 3.6700	D(x): 0.9964	D(x_out): 0.0250	D(G(z)): 0.0260 / 0.0255
[17/20][100/211]	Loss_D: 0.0284	Loss_G: 3.7169	D(x): 0.9965	D(x_out): 0.0254	D(G(z)): 0.0238 / 0.0243
[17/20][150/211]	Loss_D: 0.0272	Loss_G: 3.7249	D(x): 0.9967	D(x_out): 0.0238	D(G(z)): 0.0233 / 0.0241
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
1.0
[18/20][0/211]	Loss_D: 0.0269	Loss_G: 3.7149	D(x): 0.9967	D(x_out): 0.0237	D(G(z)): 0.0230 / 0.0244
[18/20][50/211]	Loss_D: 0.0259	Loss_G: 3.8083	D(x): 0.9968	D(x_out): 0.0217	D(G(z)): 0.0233 / 0.0222
[18/20][100/211]	Loss_D: 0.0249	Loss_G: 3.8376	D(x): 0.9970	D(x_out): 0.0219	D(G(z)): 0.0213 / 0.0216
[18/20][150/211]	Loss_D: 0.0240	Loss_G: 3.8635	D(x): 0.9971	D(x_out): 0.0216	D(G(z)): 0.0200 / 0.0210
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
1.0
[19/20][0/211]	Loss_D: 0.0237	Loss_G: 3.8946	D(x): 0.9971	D(x_out): 0.0206	D(G(z)): 0.0206 / 0.0204
[19/20][50/211]	Loss_D: 0.0229	Loss_G: 3.9235	D(x): 0.9972	D(x_out): 0.0197	D(G(z)): 0.0201 / 0.0198
[19/20][100/211]	Loss_D: 0.0220	Loss_G: 3.9450	D(x): 0.9973	D(x_out): 0.0192	D(G(z)): 0.0190 / 0.0194
[19/20][150/211]	Loss_D: 0.0211	Loss_G: 3.9834	D(x): 0.9974	D(x_out): 0.0187	D(G(z)): 0.0181 / 0.0186
1.0
ic| len(dset): 60000
Run name: mnist-fashionmnist-Balanced-4096
  0%|          | 0/60000 [00:00<?, ?it/s]  1%|          | 680/60000 [00:00<00:08, 6792.10it/s]  2%|▏         | 1372/60000 [00:00<00:08, 6863.27it/s]  3%|▎         | 2059/60000 [00:00<00:08, 6636.19it/s]  5%|▍         | 2724/60000 [00:00<00:08, 6537.33it/s]  6%|▌         | 3379/60000 [00:00<00:08, 6477.86it/s]  7%|▋         | 4028/60000 [00:00<00:08, 6414.58it/s]  8%|▊         | 4670/60000 [00:00<00:08, 6395.38it/s]  9%|▉         | 5310/60000 [00:00<00:08, 6382.16it/s] 10%|▉         | 5950/60000 [00:00<00:08, 6386.70it/s] 11%|█         | 6592/60000 [00:01<00:08, 6395.55it/s] 12%|█▏        | 7233/60000 [00:01<00:08, 6397.42it/s] 13%|█▎        | 7873/60000 [00:01<00:08, 6394.21it/s] 14%|█▍        | 8513/60000 [00:01<00:08, 6357.98it/s] 15%|█▌        | 9153/60000 [00:01<00:07, 6368.26it/s] 16%|█▋        | 9794/60000 [00:01<00:07, 6378.50it/s] 17%|█▋        | 10432/60000 [00:01<00:07, 6369.49it/s] 18%|█▊        | 11072/60000 [00:01<00:07, 6377.84it/s] 20%|█▉        | 11713/60000 [00:01<00:07, 6387.27it/s] 21%|██        | 12354/60000 [00:01<00:07, 6393.99it/s] 22%|██▏       | 12996/60000 [00:02<00:07, 6399.82it/s] 23%|██▎       | 13637/60000 [00:02<00:07, 6402.36it/s] 24%|██▍       | 14278/60000 [00:02<00:07, 6399.77it/s] 25%|██▍       | 14918/60000 [00:02<00:07, 6398.03it/s] 26%|██▌       | 15559/60000 [00:02<00:06, 6400.44it/s] 27%|██▋       | 16200/60000 [00:02<00:06, 6399.70it/s] 28%|██▊       | 16840/60000 [00:02<00:06, 6396.98it/s] 29%|██▉       | 17480/60000 [00:02<00:06, 6396.58it/s] 30%|███       | 18120/60000 [00:02<00:06, 6393.00it/s] 31%|███▏      | 18760/60000 [00:02<00:06, 6374.30it/s] 32%|███▏      | 19399/60000 [00:03<00:06, 6378.14it/s] 33%|███▎      | 20039/60000 [00:03<00:06, 6383.14it/s] 34%|███▍      | 20679/60000 [00:03<00:06, 6385.88it/s] 36%|███▌      | 21318/60000 [00:03<00:06, 6359.10it/s] 37%|███▋      | 21957/60000 [00:03<00:05, 6366.55it/s] 38%|███▊      | 22596/60000 [00:03<00:05, 6371.83it/s] 39%|███▊      | 23234/60000 [00:03<00:05, 6373.05it/s] 40%|███▉      | 23874/60000 [00:03<00:05, 6378.72it/s] 41%|████      | 24514/60000 [00:03<00:05, 6383.72it/s] 42%|████▏     | 25153/60000 [00:03<00:05, 6374.06it/s] 43%|████▎     | 25791/60000 [00:04<00:05, 6369.52it/s] 44%|████▍     | 26431/60000 [00:04<00:05, 6376.00it/s] 45%|████▌     | 27069/60000 [00:04<00:05, 6363.47it/s] 46%|████▌     | 27708/60000 [00:04<00:05, 6370.25it/s] 47%|████▋     | 28347/60000 [00:04<00:04, 6375.21it/s] 48%|████▊     | 28987/60000 [00:04<00:04, 6380.89it/s] 49%|████▉     | 29627/60000 [00:04<00:04, 6384.01it/s] 50%|█████     | 30267/60000 [00:04<00:04, 6386.04it/s] 52%|█████▏    | 30907/60000 [00:04<00:04, 6387.61it/s] 53%|█████▎    | 31547/60000 [00:04<00:04, 6389.88it/s] 54%|█████▎    | 32186/60000 [00:05<00:04, 6370.70it/s] 55%|█████▍    | 32825/60000 [00:05<00:04, 6374.42it/s] 56%|█████▌    | 33466/60000 [00:05<00:04, 6382.17it/s] 57%|█████▋    | 34105/60000 [00:05<00:04, 6384.01it/s] 58%|█████▊    | 34744/60000 [00:05<00:03, 6364.33it/s] 59%|█████▉    | 35381/60000 [00:05<00:03, 6360.76it/s] 60%|██████    | 36022/60000 [00:05<00:03, 6373.87it/s] 61%|██████    | 36660/60000 [00:05<00:03, 6373.76it/s] 62%|██████▏   | 37299/60000 [00:05<00:03, 6377.75it/s] 63%|██████▎   | 37939/60000 [00:05<00:03, 6381.57it/s] 64%|██████▍   | 38580/60000 [00:06<00:03, 6389.80it/s] 65%|██████▌   | 39221/60000 [00:06<00:03, 6394.92it/s] 66%|██████▋   | 39862/60000 [00:06<00:03, 6398.54it/s] 68%|██████▊   | 40503/60000 [00:06<00:03, 6399.75it/s] 69%|██████▊   | 41143/60000 [00:06<00:02, 6393.66it/s] 70%|██████▉   | 41784/60000 [00:06<00:02, 6395.50it/s] 71%|███████   | 42425/60000 [00:06<00:02, 6399.00it/s] 72%|███████▏  | 43065/60000 [00:06<00:02, 6383.19it/s] 73%|███████▎  | 43705/60000 [00:06<00:02, 6387.06it/s] 74%|███████▍  | 44344/60000 [00:06<00:02, 6387.36it/s] 75%|███████▍  | 44984/60000 [00:07<00:02, 6388.91it/s] 76%|███████▌  | 45624/60000 [00:07<00:02, 6389.56it/s] 77%|███████▋  | 46263/60000 [00:07<00:02, 6372.94it/s] 78%|███████▊  | 46903/60000 [00:07<00:02, 6380.52it/s] 79%|███████▉  | 47542/60000 [00:07<00:01, 6358.48it/s] 80%|████████  | 48179/60000 [00:07<00:01, 6360.34it/s] 81%|████████▏ | 48816/60000 [00:07<00:01, 6361.70it/s] 82%|████████▏ | 49454/60000 [00:07<00:01, 6364.82it/s] 83%|████████▎ | 50091/60000 [00:07<00:01, 6364.37it/s] 85%|████████▍ | 50728/60000 [00:07<00:01, 6365.60it/s] 86%|████████▌ | 51365/60000 [00:08<00:01, 6352.31it/s] 87%|████████▋ | 52003/60000 [00:08<00:01, 6359.54it/s] 88%|████████▊ | 52640/60000 [00:08<00:01, 6362.19it/s] 89%|████████▉ | 53281/60000 [00:08<00:01, 6374.33it/s] 90%|████████▉ | 53919/60000 [00:08<00:00, 6374.29it/s] 91%|█████████ | 54557/60000 [00:08<00:00, 6370.36it/s] 92%|█████████▏| 55195/60000 [00:08<00:00, 6367.24it/s] 93%|█████████▎| 55834/60000 [00:08<00:00, 6371.24it/s] 94%|█████████▍| 56472/60000 [00:08<00:00, 6370.29it/s] 95%|█████████▌| 57112/60000 [00:08<00:00, 6376.67it/s] 96%|█████████▋| 57752/60000 [00:09<00:00, 6381.37it/s] 97%|█████████▋| 58391/60000 [00:09<00:00, 6382.42it/s] 98%|█████████▊| 59030/60000 [00:09<00:00, 6382.44it/s] 99%|█████████▉| 59669/60000 [00:09<00:00, 6343.08it/s]100%|██████████| 60000/60000 [00:09<00:00, 6385.59it/s]
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 384798.53it/s]
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
ic| len(dset): 60000
MNIST-FashionMNIST InD test dataset loaded with 10000 samples.
  0%|          | 0/60000 [00:00<?, ?it/s]  1%|          | 690/60000 [00:00<00:08, 6893.32it/s]  2%|▏         | 1381/60000 [00:00<00:08, 6902.04it/s]  3%|▎         | 2072/60000 [00:00<00:08, 6905.22it/s]  5%|▍         | 2766/60000 [00:00<00:08, 6918.27it/s]  6%|▌         | 3461/60000 [00:00<00:08, 6926.99it/s]  7%|▋         | 4155/60000 [00:00<00:08, 6931.06it/s]  8%|▊         | 4849/60000 [00:00<00:07, 6932.20it/s]  9%|▉         | 5545/60000 [00:00<00:07, 6938.72it/s] 10%|█         | 6241/60000 [00:00<00:07, 6944.78it/s] 12%|█▏        | 6938/60000 [00:01<00:07, 6949.81it/s] 13%|█▎        | 7633/60000 [00:01<00:07, 6949.68it/s] 14%|█▍        | 8328/60000 [00:01<00:07, 6912.18it/s] 15%|█▌        | 9020/60000 [00:01<00:10, 4875.64it/s] 16%|█▌        | 9713/60000 [00:01<00:09, 5353.82it/s] 17%|█▋        | 10407/60000 [00:01<00:08, 5748.92it/s] 19%|█▊        | 11102/60000 [00:01<00:08, 6062.64it/s] 20%|█▉        | 11797/60000 [00:01<00:07, 6304.26it/s] 21%|██        | 12491/60000 [00:01<00:07, 6481.34it/s] 22%|██▏       | 13177/60000 [00:02<00:07, 6589.40it/s] 23%|██▎       | 13871/60000 [00:02<00:06, 6690.08it/s] 24%|██▍       | 14566/60000 [00:02<00:06, 6764.51it/s] 25%|██▌       | 15261/60000 [00:02<00:06, 6817.86it/s] 27%|██▋       | 15955/60000 [00:02<00:06, 6853.58it/s] 28%|██▊       | 16648/60000 [00:02<00:06, 6873.26it/s] 29%|██▉       | 17339/60000 [00:02<00:06, 6871.31it/s] 30%|███       | 18032/60000 [00:02<00:06, 6886.88it/s] 31%|███       | 18725/60000 [00:02<00:05, 6897.31it/s] 32%|███▏      | 19419/60000 [00:02<00:05, 6909.28it/s] 34%|███▎      | 20111/60000 [00:03<00:05, 6909.68it/s] 35%|███▍      | 20803/60000 [00:03<00:05, 6912.28it/s] 36%|███▌      | 21497/60000 [00:03<00:05, 6918.58it/s] 37%|███▋      | 22191/60000 [00:03<00:05, 6924.37it/s] 38%|███▊      | 22884/60000 [00:03<00:05, 6924.83it/s] 39%|███▉      | 23578/60000 [00:03<00:05, 6927.41it/s] 40%|████      | 24271/60000 [00:03<00:05, 6927.37it/s] 42%|████▏     | 24964/60000 [00:03<00:05, 6924.93it/s] 43%|████▎     | 25657/60000 [00:03<00:04, 6901.82it/s] 44%|████▍     | 26349/60000 [00:03<00:04, 6907.13it/s] 45%|████▌     | 27040/60000 [00:04<00:04, 6894.05it/s] 46%|████▌     | 27734/60000 [00:04<00:04, 6905.34it/s] 47%|████▋     | 28428/60000 [00:04<00:04, 6913.00it/s] 49%|████▊     | 29122/60000 [00:04<00:04, 6918.60it/s] 50%|████▉     | 29816/60000 [00:04<00:04, 6923.88it/s] 51%|█████     | 30509/60000 [00:04<00:04, 6923.08it/s] 52%|█████▏    | 31202/60000 [00:04<00:04, 6923.77it/s] 53%|█████▎    | 31895/60000 [00:04<00:04, 6924.13it/s] 54%|█████▍    | 32588/60000 [00:04<00:03, 6918.83it/s] 55%|█████▌    | 33281/60000 [00:04<00:03, 6921.46it/s] 57%|█████▋    | 33974/60000 [00:05<00:03, 6904.26it/s] 58%|█████▊    | 34668/60000 [00:05<00:03, 6913.44it/s] 59%|█████▉    | 35362/60000 [00:05<00:03, 6919.59it/s] 60%|██████    | 36056/60000 [00:05<00:03, 6923.16it/s] 61%|██████    | 36749/60000 [00:05<00:03, 6924.52it/s] 62%|██████▏   | 37442/60000 [00:05<00:03, 6925.26it/s] 64%|██████▎   | 38135/60000 [00:05<00:03, 6924.09it/s] 65%|██████▍   | 38828/60000 [00:05<00:03, 6921.63it/s] 66%|██████▌   | 39521/60000 [00:05<00:02, 6916.21it/s] 67%|██████▋   | 40213/60000 [00:05<00:02, 6911.55it/s] 68%|██████▊   | 40905/60000 [00:06<00:02, 6887.92it/s] 69%|██████▉   | 41597/60000 [00:06<00:02, 6897.28it/s] 70%|███████   | 42287/60000 [00:06<00:02, 6887.19it/s] 72%|███████▏  | 42981/60000 [00:06<00:02, 6901.10it/s] 73%|███████▎  | 43672/60000 [00:06<00:02, 6902.03it/s] 74%|███████▍  | 44363/60000 [00:06<00:02, 6901.79it/s] 75%|███████▌  | 45054/60000 [00:06<00:02, 6903.79it/s] 76%|███████▌  | 45746/60000 [00:06<00:02, 6905.76it/s] 77%|███████▋  | 46437/60000 [00:06<00:01, 6905.48it/s] 79%|███████▊  | 47128/60000 [00:06<00:01, 6906.52it/s] 80%|███████▉  | 47819/60000 [00:07<00:01, 6905.61it/s] 81%|████████  | 48510/60000 [00:07<00:01, 6906.59it/s] 82%|████████▏ | 49201/60000 [00:07<00:01, 6905.31it/s] 83%|████████▎ | 49892/60000 [00:07<00:01, 6901.22it/s] 84%|████████▍ | 50583/60000 [00:07<00:01, 6887.17it/s] 85%|████████▌ | 51273/60000 [00:07<00:01, 6889.93it/s] 87%|████████▋ | 51964/60000 [00:07<00:01, 6892.98it/s] 88%|████████▊ | 52654/60000 [00:07<00:01, 6791.58it/s] 89%|████████▉ | 53334/60000 [00:07<00:01, 6661.93it/s] 90%|█████████ | 54001/60000 [00:07<00:00, 6571.79it/s] 91%|█████████ | 54659/60000 [00:08<00:00, 6486.40it/s] 92%|█████████▏| 55309/60000 [00:08<00:00, 6448.12it/s] 93%|█████████▎| 55955/60000 [00:08<00:00, 6424.24it/s] 94%|█████████▍| 56598/60000 [00:08<00:00, 6404.47it/s] 95%|█████████▌| 57239/60000 [00:08<00:00, 6392.98it/s] 96%|█████████▋| 57879/60000 [00:08<00:00, 6384.49it/s] 98%|█████████▊| 58518/60000 [00:08<00:00, 6359.85it/s] 99%|█████████▊| 59155/60000 [00:08<00:00, 6360.32it/s]100%|█████████▉| 59792/60000 [00:08<00:00, 6334.39it/s]100%|██████████| 60000/60000 [00:08<00:00, 6728.61it/s]
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 395689.06it/s]
MNIST-FashionMNIST OOD testing dataset loaded with 10000 samples.
Out datasets: ['mnist-fashionmnist']

 best_
mnist-fashionmnist_0.0:   0%|          | 0/40 [00:00<?, ?it/s]mnist-fashionmnist_0.0:   2%|▎         | 1/40 [00:01<01:03,  1.63s/it]mnist-fashionmnist_0.0:  10%|█         | 4/40 [00:01<00:12,  2.90it/s]mnist-fashionmnist_0.0:  20%|██        | 8/40 [00:01<00:04,  6.48it/s]mnist-fashionmnist_0.0:  28%|██▊       | 11/40 [00:02<00:03,  8.87it/s]mnist-fashionmnist_0.0:  35%|███▌      | 14/40 [00:02<00:02, 10.59it/s]mnist-fashionmnist_0.0:  40%|████      | 16/40 [00:02<00:02, 11.78it/s]mnist-fashionmnist_0.0:  45%|████▌     | 18/40 [00:02<00:01, 12.96it/s]mnist-fashionmnist_0.0:  50%|█████     | 20/40 [00:02<00:01, 13.87it/s]mnist-fashionmnist_0.0:  55%|█████▌    | 22/40 [00:02<00:01, 14.66it/s]mnist-fashionmnist_0.0:  60%|██████    | 24/40 [00:02<00:01, 15.64it/s]mnist-fashionmnist_0.0:  65%|██████▌   | 26/40 [00:02<00:00, 15.67it/s]mnist-fashionmnist_0.0:  70%|███████   | 28/40 [00:03<00:00, 16.49it/s]mnist-fashionmnist_0.0:  75%|███████▌  | 30/40 [00:03<00:00, 16.34it/s]mnist-fashionmnist_0.0:  80%|████████  | 32/40 [00:03<00:00, 17.15it/s]mnist-fashionmnist_0.0:  85%|████████▌ | 34/40 [00:03<00:00, 17.05it/s]mnist-fashionmnist_0.0:  90%|█████████ | 36/40 [00:03<00:00, 17.38it/s]mnist-fashionmnist_0.0:  95%|█████████▌| 38/40 [00:03<00:00, 17.29it/s]mnist-fashionmnist_0.0: 100%|██████████| 40/40 [00:03<00:00, 10.60it/s]
mnist-fashionmnist_0.031:   0%|          | 0/40 [00:00<?, ?it/s]mnist-fashionmnist_0.031:   2%|▎         | 1/40 [00:11<07:12, 11.09s/it]mnist-fashionmnist_0.031:   5%|▌         | 2/40 [00:20<06:28, 10.23s/it]mnist-fashionmnist_0.031:   8%|▊         | 3/40 [00:30<06:08,  9.96s/it]mnist-fashionmnist_0.031:  10%|█         | 4/40 [00:40<05:54,  9.84s/it]mnist-fashionmnist_0.031:  12%|█▎        | 5/40 [00:49<05:42,  9.77s/it]mnist-fashionmnist_0.031:  15%|█▌        | 6/40 [00:59<05:30,  9.73s/it]mnist-fashionmnist_0.031:  18%|█▊        | 7/40 [01:08<05:20,  9.71s/it]mnist-fashionmnist_0.031:  20%|██        | 8/40 [01:18<05:10,  9.70s/it]mnist-fashionmnist_0.031:  22%|██▎       | 9/40 [01:28<05:00,  9.69s/it]mnist-fashionmnist_0.031:  25%|██▌       | 10/40 [01:38<04:50,  9.69s/it]mnist-fashionmnist_0.031:  28%|██▊       | 11/40 [01:47<04:40,  9.68s/it]mnist-fashionmnist_0.031:  30%|███       | 12/40 [01:57<04:31,  9.68s/it]mnist-fashionmnist_0.031:  32%|███▎      | 13/40 [02:07<04:21,  9.68s/it]mnist-fashionmnist_0.031:  35%|███▌      | 14/40 [02:16<04:11,  9.68s/it]mnist-fashionmnist_0.031:  38%|███▊      | 15/40 [02:26<04:02,  9.68s/it]mnist-fashionmnist_0.031:  40%|████      | 16/40 [02:36<03:52,  9.69s/it]mnist-fashionmnist_0.031:  42%|████▎     | 17/40 [02:45<03:42,  9.69s/it]mnist-fashionmnist_0.031:  45%|████▌     | 18/40 [02:55<03:33,  9.68s/it]mnist-fashionmnist_0.031:  48%|████▊     | 19/40 [03:05<03:23,  9.68s/it]mnist-fashionmnist_0.031:  50%|█████     | 20/40 [03:14<03:13,  9.68s/it]mnist-fashionmnist_0.031:  52%|█████▎    | 21/40 [03:24<03:04,  9.69s/it]mnist-fashionmnist_0.031:  55%|█████▌    | 22/40 [03:34<02:54,  9.69s/it]mnist-fashionmnist_0.031:  57%|█████▊    | 23/40 [03:43<02:44,  9.69s/it]mnist-fashionmnist_0.031:  60%|██████    | 24/40 [03:53<02:35,  9.69s/it]mnist-fashionmnist_0.031:  62%|██████▎   | 25/40 [04:03<02:25,  9.69s/it]mnist-fashionmnist_0.031:  65%|██████▌   | 26/40 [04:12<02:15,  9.69s/it]mnist-fashionmnist_0.031:  68%|██████▊   | 27/40 [04:22<02:05,  9.69s/it]mnist-fashionmnist_0.031:  70%|███████   | 28/40 [04:32<01:56,  9.69s/it]mnist-fashionmnist_0.031:  72%|███████▎  | 29/40 [04:42<01:46,  9.69s/it]mnist-fashionmnist_0.031:  75%|███████▌  | 30/40 [04:51<01:36,  9.69s/it]mnist-fashionmnist_0.031:  78%|███████▊  | 31/40 [05:01<01:27,  9.69s/it]mnist-fashionmnist_0.031:  80%|████████  | 32/40 [05:11<01:17,  9.69s/it]mnist-fashionmnist_0.031:  82%|████████▎ | 33/40 [05:20<01:07,  9.68s/it]mnist-fashionmnist_0.031:  85%|████████▌ | 34/40 [05:30<00:58,  9.69s/it]mnist-fashionmnist_0.031:  88%|████████▊ | 35/40 [05:40<00:48,  9.68s/it]mnist-fashionmnist_0.031:  90%|█████████ | 36/40 [05:49<00:38,  9.68s/it]mnist-fashionmnist_0.031:  92%|█████████▎| 37/40 [05:59<00:29,  9.68s/it]mnist-fashionmnist_0.031:  95%|█████████▌| 38/40 [06:09<00:19,  9.67s/it]mnist-fashionmnist_0.031:  98%|█████████▊| 39/40 [06:18<00:09,  9.67s/it]mnist-fashionmnist_0.031: 100%|██████████| 40/40 [06:20<00:00,  7.14s/it]mnist-fashionmnist_0.031: 100%|██████████| 40/40 [06:20<00:00,  9.50s/it]
mnist-fashionmnist_0.0:   0%|          | 0/40 [00:00<?, ?it/s]mnist-fashionmnist_0.0:   2%|▎         | 1/40 [00:00<00:36,  1.08it/s]mnist-fashionmnist_0.0:   8%|▊         | 3/40 [00:01<00:10,  3.51it/s]mnist-fashionmnist_0.0:  15%|█▌        | 6/40 [00:01<00:04,  7.23it/s]mnist-fashionmnist_0.0:  20%|██        | 8/40 [00:01<00:03,  9.15it/s]mnist-fashionmnist_0.0:  25%|██▌       | 10/40 [00:01<00:02, 10.89it/s]mnist-fashionmnist_0.0:  30%|███       | 12/40 [00:01<00:02, 12.39it/s]mnist-fashionmnist_0.0:  35%|███▌      | 14/40 [00:01<00:01, 13.50it/s]mnist-fashionmnist_0.0:  40%|████      | 16/40 [00:01<00:01, 14.62it/s]mnist-fashionmnist_0.0:  45%|████▌     | 18/40 [00:01<00:01, 15.56it/s]mnist-fashionmnist_0.0:  50%|█████     | 20/40 [00:02<00:01, 15.77it/s]mnist-fashionmnist_0.0:  55%|█████▌    | 22/40 [00:02<00:01, 16.39it/s]mnist-fashionmnist_0.0:  60%|██████    | 24/40 [00:02<00:00, 16.72it/s]mnist-fashionmnist_0.0:  65%|██████▌   | 26/40 [00:02<00:00, 16.84it/s]mnist-fashionmnist_0.0:  70%|███████   | 28/40 [00:02<00:00, 16.79it/s]mnist-fashionmnist_0.0:  75%|███████▌  | 30/40 [00:02<00:00, 16.96it/s]mnist-fashionmnist_0.0:  80%|████████  | 32/40 [00:02<00:00, 17.09it/s]mnist-fashionmnist_0.0:  85%|████████▌ | 34/40 [00:02<00:00, 16.34it/s]mnist-fashionmnist_0.0:  90%|█████████ | 36/40 [00:02<00:00, 17.01it/s]mnist-fashionmnist_0.0:  95%|█████████▌| 38/40 [00:03<00:00, 16.38it/s]mnist-fashionmnist_0.0: 100%|██████████| 40/40 [00:03<00:00, 12.54it/s]
mnist-fashionmnist_0.031:   0%|          | 0/40 [00:00<?, ?it/s]mnist-fashionmnist_0.031:   2%|▎         | 1/40 [00:10<06:51, 10.55s/it]mnist-fashionmnist_0.031:   5%|▌         | 2/40 [00:20<06:21, 10.04s/it]mnist-fashionmnist_0.031:   8%|▊         | 3/40 [00:29<06:05,  9.87s/it]mnist-fashionmnist_0.031:  10%|█         | 4/40 [00:39<05:52,  9.80s/it]mnist-fashionmnist_0.031:  12%|█▎        | 5/40 [00:49<05:41,  9.75s/it]mnist-fashionmnist_0.031:  15%|█▌        | 6/40 [00:58<05:30,  9.73s/it]mnist-fashionmnist_0.031:  18%|█▊        | 7/40 [01:08<05:20,  9.71s/it]mnist-fashionmnist_0.031:  20%|██        | 8/40 [01:18<05:10,  9.70s/it]mnist-fashionmnist_0.031:  22%|██▎       | 9/40 [01:27<05:00,  9.69s/it]mnist-fashionmnist_0.031:  25%|██▌       | 10/40 [01:37<04:50,  9.69s/it]mnist-fashionmnist_0.031:  28%|██▊       | 11/40 [01:47<04:41,  9.69s/it]mnist-fashionmnist_0.031:  30%|███       | 12/40 [01:57<04:31,  9.69s/it]mnist-fashionmnist_0.031:  32%|███▎      | 13/40 [02:06<04:21,  9.68s/it]mnist-fashionmnist_0.031:  35%|███▌      | 14/40 [02:16<04:11,  9.68s/it]mnist-fashionmnist_0.031:  38%|███▊      | 15/40 [02:26<04:02,  9.68s/it]mnist-fashionmnist_0.031:  40%|████      | 16/40 [02:35<03:52,  9.68s/it]mnist-fashionmnist_0.031:  42%|████▎     | 17/40 [02:45<03:42,  9.69s/it]mnist-fashionmnist_0.031:  45%|████▌     | 18/40 [02:55<03:33,  9.69s/it]mnist-fashionmnist_0.031:  48%|████▊     | 19/40 [03:04<03:23,  9.69s/it]mnist-fashionmnist_0.031:  50%|█████     | 20/40 [03:14<03:13,  9.69s/it]mnist-fashionmnist_0.031:  52%|█████▎    | 21/40 [03:24<03:04,  9.69s/it]mnist-fashionmnist_0.031:  55%|█████▌    | 22/40 [03:33<02:54,  9.68s/it]mnist-fashionmnist_0.031:  57%|█████▊    | 23/40 [03:43<02:44,  9.69s/it]mnist-fashionmnist_0.031:  60%|██████    | 24/40 [03:53<02:34,  9.69s/it]mnist-fashionmnist_0.031:  62%|██████▎   | 25/40 [04:02<02:25,  9.68s/it]mnist-fashionmnist_0.031:  65%|██████▌   | 26/40 [04:12<02:15,  9.69s/it]mnist-fashionmnist_0.031:  68%|██████▊   | 27/40 [04:22<02:05,  9.69s/it]mnist-fashionmnist_0.031:  70%|███████   | 28/40 [04:31<01:56,  9.68s/it]mnist-fashionmnist_0.031:  72%|███████▎  | 29/40 [04:41<01:46,  9.68s/it]mnist-fashionmnist_0.031:  75%|███████▌  | 30/40 [04:51<01:36,  9.68s/it]mnist-fashionmnist_0.031:  78%|███████▊  | 31/40 [05:01<01:27,  9.68s/it]mnist-fashionmnist_0.031:  80%|████████  | 32/40 [05:10<01:17,  9.68s/it]mnist-fashionmnist_0.031:  82%|████████▎ | 33/40 [05:20<01:07,  9.68s/it]mnist-fashionmnist_0.031:  85%|████████▌ | 34/40 [05:30<00:58,  9.68s/it]mnist-fashionmnist_0.031:  88%|████████▊ | 35/40 [05:39<00:48,  9.69s/it]mnist-fashionmnist_0.031:  90%|█████████ | 36/40 [05:49<00:38,  9.68s/it]mnist-fashionmnist_0.031:  92%|█████████▎| 37/40 [05:59<00:29,  9.68s/it]mnist-fashionmnist_0.031:  95%|█████████▌| 38/40 [06:08<00:19,  9.68s/it]mnist-fashionmnist_0.031:  98%|█████████▊| 39/40 [06:18<00:09,  9.68s/it]mnist-fashionmnist_0.031: 100%|██████████| 40/40 [06:19<00:00,  7.12s/it]mnist-fashionmnist_0.031: 100%|██████████| 40/40 [06:19<00:00,  9.49s/it]

dataset: mnist-fashionmnist

just in attacked
eps= 0.0 : 0.9999998999999999
TPR at 0.95 TNR 1.0
eps= 0.0313 : 0.99999971

just out attacked
eps= 0.0 : 0.9999998999999999
eps= 0.0313 : 0.99999965

both attacked
eps= 0.0 : 0.9999998999999999
eps= 0.0313 : 0.99999867
