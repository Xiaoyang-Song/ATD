/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Run name: cifar10-svhn-Balanced-4096
Files already downloaded and verified
Out-of-distribution dataset size: 40960
Validation set size: 10000
Starting Training Loop...
[0/20][0/176]	Loss_D: 1.4235	Loss_G: 0.6926	D(x): 0.4885	D(x_out): 0.5214	D(G(z)): 0.4902 / 0.5003
[0/20][50/176]	Loss_D: 0.8446	Loss_G: 0.8409	D(x): 0.7167	D(x_out): 0.4130	D(G(z)): 0.3760 / 0.4316
[0/20][100/176]	Loss_D: 0.7205	Loss_G: 1.0949	D(x): 0.7724	D(x_out): 0.3856	D(G(z)): 0.3445 / 0.3352
[0/20][150/176]	Loss_D: 0.6500	Loss_G: 1.1290	D(x): 0.8060	D(x_out): 0.3645	D(G(z)): 0.3270 / 0.3238
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
0.9996459375
checkpoint!
[1/20][0/176]	Loss_D: 0.6409	Loss_G: 1.1458	D(x): 0.8096	D(x_out): 0.3598	D(G(z)): 0.3248 / 0.3183
[1/20][50/176]	Loss_D: 0.5853	Loss_G: 1.1914	D(x): 0.8368	D(x_out): 0.3459	D(G(z)): 0.3065 / 0.3041
[1/20][100/176]	Loss_D: 0.5243	Loss_G: 1.2492	D(x): 0.8626	D(x_out): 0.3251	D(G(z)): 0.2900 / 0.2870
[1/20][150/176]	Loss_D: 0.5014	Loss_G: 1.2960	D(x): 0.8714	D(x_out): 0.3123	D(G(z)): 0.2780 / 0.2739
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
0.9998370703125001
checkpoint!
[2/20][0/176]	Loss_D: 0.4817	Loss_G: 1.3028	D(x): 0.8789	D(x_out): 0.3063	D(G(z)): 0.2739 / 0.2720
[2/20][50/176]	Loss_D: 0.4458	Loss_G: 1.3546	D(x): 0.8940	D(x_out): 0.2944	D(G(z)): 0.2584 / 0.2583
[2/20][100/176]	Loss_D: 0.4188	Loss_G: 1.4218	D(x): 0.9050	D(x_out): 0.2808	D(G(z)): 0.2457 / 0.2415
[2/20][150/176]	Loss_D: 0.3974	Loss_G: 1.4577	D(x): 0.9146	D(x_out): 0.2732	D(G(z)): 0.2323 / 0.2330
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
0.9997919921874999
[3/20][0/176]	Loss_D: 0.3785	Loss_G: 1.4704	D(x): 0.9201	D(x_out): 0.2671	D(G(z)): 0.2285 / 0.2300
[3/20][50/176]	Loss_D: 0.3531	Loss_G: 1.5008	D(x): 0.9276	D(x_out): 0.2487	D(G(z)): 0.2226 / 0.2231
[3/20][100/176]	Loss_D: 0.3360	Loss_G: 1.6142	D(x): 0.9305	D(x_out): 0.2366	D(G(z)): 0.2102 / 0.1993
[3/20][150/176]	Loss_D: 0.3164	Loss_G: 1.6225	D(x): 0.9420	D(x_out): 0.2353	D(G(z)): 0.1934 / 0.1976
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
0.99982203125
[4/20][0/176]	Loss_D: 0.3178	Loss_G: 1.5928	D(x): 0.9406	D(x_out): 0.2292	D(G(z)): 0.1972 / 0.2036
[4/20][50/176]	Loss_D: 0.2829	Loss_G: 1.6947	D(x): 0.9522	D(x_out): 0.2209	D(G(z)): 0.1814 / 0.1839
[4/20][100/176]	Loss_D: 0.2806	Loss_G: 1.7726	D(x): 0.9467	D(x_out): 0.2096	D(G(z)): 0.1730 / 0.1701
[4/20][150/176]	Loss_D: 0.2566	Loss_G: 1.7960	D(x): 0.9570	D(x_out): 0.1963	D(G(z)): 0.1685 / 0.1662
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
0.99990484375
checkpoint!
[5/20][0/176]	Loss_D: 0.2616	Loss_G: 1.7904	D(x): 0.9563	D(x_out): 0.2049	D(G(z)): 0.1606 / 0.1671
[5/20][50/176]	Loss_D: 0.2438	Loss_G: 1.9161	D(x): 0.9571	D(x_out): 0.1869	D(G(z)): 0.1572 / 0.1474
[5/20][100/176]	Loss_D: 0.2467	Loss_G: 1.8907	D(x): 0.9603	D(x_out): 0.1834	D(G(z)): 0.1498 / 0.1512
[5/20][150/176]	Loss_D: 0.2218	Loss_G: 1.9410	D(x): 0.9652	D(x_out): 0.1675	D(G(z)): 0.1463 / 0.1438
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
0.9998787499999999
[6/20][0/176]	Loss_D: 0.2175	Loss_G: 1.9667	D(x): 0.9668	D(x_out): 0.1831	D(G(z)): 0.1320 / 0.1401
[6/20][50/176]	Loss_D: 0.2254	Loss_G: 2.0791	D(x): 0.9607	D(x_out): 0.1682	D(G(z)): 0.1317 / 0.1252
[6/20][100/176]	Loss_D: 0.1861	Loss_G: 2.0658	D(x): 0.9727	D(x_out): 0.1560	D(G(z)): 0.1243 / 0.1270
[6/20][150/176]	Loss_D: 0.1822	Loss_G: 2.0901	D(x): 0.9715	D(x_out): 0.1409	D(G(z)): 0.1251 / 0.1240
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
0.9998904296875
[7/20][0/176]	Loss_D: 0.1732	Loss_G: 2.1666	D(x): 0.9754	D(x_out): 0.1471	D(G(z)): 0.1177 / 0.1148
[7/20][50/176]	Loss_D: 0.1672	Loss_G: 2.1451	D(x): 0.9739	D(x_out): 0.1402	D(G(z)): 0.1122 / 0.1173
[7/20][100/176]	Loss_D: 0.1718	Loss_G: 2.2510	D(x): 0.9715	D(x_out): 0.1338	D(G(z)): 0.1100 / 0.1055
[7/20][150/176]	Loss_D: 0.1613	Loss_G: 2.2289	D(x): 0.9787	D(x_out): 0.1357	D(G(z)): 0.1013 / 0.1079
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
0.9997737109375
[8/20][0/176]	Loss_D: 0.1586	Loss_G: 2.3364	D(x): 0.9776	D(x_out): 0.1288	D(G(z)): 0.0997 / 0.0969
[8/20][50/176]	Loss_D: 0.1452	Loss_G: 2.3634	D(x): 0.9753	D(x_out): 0.1202	D(G(z)): 0.0957 / 0.0943
[8/20][100/176]	Loss_D: 0.1424	Loss_G: 2.3348	D(x): 0.9817	D(x_out): 0.1196	D(G(z)): 0.0938 / 0.0971
[8/20][150/176]	Loss_D: 0.1595	Loss_G: 2.5001	D(x): 0.9729	D(x_out): 0.1208	D(G(z)): 0.0871 / 0.0822
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
0.9998445312500001
[9/20][0/176]	Loss_D: 0.1329	Loss_G: 2.3862	D(x): 0.9817	D(x_out): 0.1138	D(G(z)): 0.0854 / 0.0922
[9/20][50/176]	Loss_D: 0.1265	Loss_G: 2.3961	D(x): 0.9803	D(x_out): 0.1003	D(G(z)): 0.0888 / 0.0913
[9/20][100/176]	Loss_D: 0.1453	Loss_G: 2.5317	D(x): 0.9727	D(x_out): 0.1073	D(G(z)): 0.0793 / 0.0797
[9/20][150/176]	Loss_D: 0.1450	Loss_G: 2.6176	D(x): 0.9755	D(x_out): 0.1102	D(G(z)): 0.0732 / 0.0732
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
0.9997729687500001
[10/20][0/176]	Loss_D: 0.1174	Loss_G: 2.5642	D(x): 0.9840	D(x_out): 0.0998	D(G(z)): 0.0733 / 0.0771
[10/20][50/176]	Loss_D: 0.1170	Loss_G: 2.5793	D(x): 0.9799	D(x_out): 0.0917	D(G(z)): 0.0723 / 0.0760
[10/20][100/176]	Loss_D: 0.1184	Loss_G: 2.8242	D(x): 0.9790	D(x_out): 0.0967	D(G(z)): 0.0648 / 0.0595
[10/20][150/176]	Loss_D: 0.1015	Loss_G: 2.6500	D(x): 0.9896	D(x_out): 0.0900	D(G(z)): 0.0628 / 0.0709
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
0.9998497656249999
[11/20][0/176]	Loss_D: 0.0992	Loss_G: 2.6988	D(x): 0.9844	D(x_out): 0.0864	D(G(z)): 0.0649 / 0.0675
[11/20][50/176]	Loss_D: 0.1087	Loss_G: 2.6979	D(x): 0.9833	D(x_out): 0.0805	D(G(z)): 0.0638 / 0.0675
[11/20][100/176]	Loss_D: 0.0930	Loss_G: 2.9399	D(x): 0.9806	D(x_out): 0.0693	D(G(z)): 0.0606 / 0.0530
[11/20][150/176]	Loss_D: 0.1118	Loss_G: 2.7990	D(x): 0.9803	D(x_out): 0.0773	D(G(z)): 0.0602 / 0.0611
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
0.9995744140625
[12/20][0/176]	Loss_D: 0.1069	Loss_G: 2.9296	D(x): 0.9760	D(x_out): 0.0744	D(G(z)): 0.0588 / 0.0536
[12/20][50/176]	Loss_D: 0.1047	Loss_G: 2.9083	D(x): 0.9835	D(x_out): 0.0765	D(G(z)): 0.0561 / 0.0548
[12/20][100/176]	Loss_D: 0.0842	Loss_G: 2.9714	D(x): 0.9891	D(x_out): 0.0727	D(G(z)): 0.0496 / 0.0514
[12/20][150/176]	Loss_D: 0.0897	Loss_G: 3.0165	D(x): 0.9819	D(x_out): 0.0656	D(G(z)): 0.0507 / 0.0492
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
0.999838515625
[13/20][0/176]	Loss_D: 0.0756	Loss_G: 2.9483	D(x): 0.9891	D(x_out): 0.0721	D(G(z)): 0.0451 / 0.0526
[13/20][50/176]	Loss_D: 0.0906	Loss_G: 3.0364	D(x): 0.9879	D(x_out): 0.0707	D(G(z)): 0.0440 / 0.0482
[13/20][100/176]	Loss_D: 0.0738	Loss_G: 3.3533	D(x): 0.9895	D(x_out): 0.0672	D(G(z)): 0.0413 / 0.0351
[13/20][150/176]	Loss_D: 0.0740	Loss_G: 3.2198	D(x): 0.9877	D(x_out): 0.0593	D(G(z)): 0.0411 / 0.0401
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
0.9997429296875
[14/20][0/176]	Loss_D: 0.0616	Loss_G: 3.1755	D(x): 0.9898	D(x_out): 0.0552	D(G(z)): 0.0423 / 0.0419
[14/20][50/176]	Loss_D: 0.0779	Loss_G: 3.1822	D(x): 0.9833	D(x_out): 0.0561	D(G(z)): 0.0432 / 0.0417
[14/20][100/176]	Loss_D: 0.0792	Loss_G: 3.0493	D(x): 0.9888	D(x_out): 0.0572	D(G(z)): 0.0418 / 0.0476
[14/20][150/176]	Loss_D: 0.0719	Loss_G: 3.2240	D(x): 0.9903	D(x_out): 0.0566	D(G(z)): 0.0364 / 0.0400
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
0.9998994140625
[15/20][0/176]	Loss_D: 0.0590	Loss_G: 3.4642	D(x): 0.9940	D(x_out): 0.0601	D(G(z)): 0.0328 / 0.0314
[15/20][50/176]	Loss_D: 0.0550	Loss_G: 3.3164	D(x): 0.9892	D(x_out): 0.0427	D(G(z)): 0.0389 / 0.0365
[15/20][100/176]	Loss_D: 0.0746	Loss_G: 3.3761	D(x): 0.9905	D(x_out): 0.0560	D(G(z)): 0.0355 / 0.0344
[15/20][150/176]	Loss_D: 0.0489	Loss_G: 3.3713	D(x): 0.9914	D(x_out): 0.0432	D(G(z)): 0.0332 / 0.0345
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
0.9997546484375001
[16/20][0/176]	Loss_D: 0.0629	Loss_G: 3.2408	D(x): 0.9881	D(x_out): 0.0430	D(G(z)): 0.0368 / 0.0395
[16/20][50/176]	Loss_D: 0.0586	Loss_G: 3.4205	D(x): 0.9913	D(x_out): 0.0432	D(G(z)): 0.0332 / 0.0329
[16/20][100/176]	Loss_D: 0.0497	Loss_G: 3.5494	D(x): 0.9908	D(x_out): 0.0411	D(G(z)): 0.0289 / 0.0289
[16/20][150/176]	Loss_D: 0.0531	Loss_G: 3.7838	D(x): 0.9879	D(x_out): 0.0443	D(G(z)): 0.0269 / 0.0229
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
0.9995578125
[17/20][0/176]	Loss_D: 0.0678	Loss_G: 3.5124	D(x): 0.9881	D(x_out): 0.0441	D(G(z)): 0.0313 / 0.0300
[17/20][50/176]	Loss_D: 0.0550	Loss_G: 3.7473	D(x): 0.9927	D(x_out): 0.0438	D(G(z)): 0.0253 / 0.0237
[17/20][100/176]	Loss_D: 0.0638	Loss_G: 3.6032	D(x): 0.9852	D(x_out): 0.0296	D(G(z)): 0.0309 / 0.0274
[17/20][150/176]	Loss_D: 0.0446	Loss_G: 3.7663	D(x): 0.9931	D(x_out): 0.0342	D(G(z)): 0.0254 / 0.0233
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
0.9998276953124999
[18/20][0/176]	Loss_D: 0.0448	Loss_G: 3.6839	D(x): 0.9910	D(x_out): 0.0278	D(G(z)): 0.0283 / 0.0253
[18/20][50/176]	Loss_D: 0.0500	Loss_G: 3.6937	D(x): 0.9875	D(x_out): 0.0291	D(G(z)): 0.0278 / 0.0250
[18/20][100/176]	Loss_D: 0.0406	Loss_G: 3.6060	D(x): 0.9944	D(x_out): 0.0359	D(G(z)): 0.0248 / 0.0274
[18/20][150/176]	Loss_D: 0.0415	Loss_G: 3.8549	D(x): 0.9947	D(x_out): 0.0351	D(G(z)): 0.0227 / 0.0213
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
0.9996467578125
[19/20][0/176]	Loss_D: 0.0389	Loss_G: 3.6022	D(x): 0.9933	D(x_out): 0.0311	D(G(z)): 0.0243 / 0.0275
[19/20][50/176]	Loss_D: 0.0388	Loss_G: 3.8249	D(x): 0.9952	D(x_out): 0.0314	D(G(z)): 0.0220 / 0.0220
[19/20][100/176]	Loss_D: 0.0338	Loss_G: 3.8522	D(x): 0.9934	D(x_out): 0.0257	D(G(z)): 0.0219 / 0.0214
[19/20][150/176]	Loss_D: 0.0536	Loss_G: 3.9841	D(x): 0.9932	D(x_out): 0.0350	D(G(z)): 0.0204 / 0.0188
0.9998644140625
/home/xysong/.conda/envs/OoD/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Run name: cifar10-svhn-Balanced-4096
Files already downloaded and verified
Using downloaded and verified file: ./data/test_32x32.mat
Out datasets: ['cifar10-svhn']

 best_
cifar10-svhn_0.0:   0%|          | 0/40 [00:00<?, ?it/s]cifar10-svhn_0.0:   2%|▎         | 1/40 [00:01<00:54,  1.39s/it]cifar10-svhn_0.0:  10%|█         | 4/40 [00:01<00:10,  3.35it/s]cifar10-svhn_0.0:  18%|█▊        | 7/40 [00:01<00:05,  6.19it/s]cifar10-svhn_0.0:  25%|██▌       | 10/40 [00:01<00:03,  9.36it/s]cifar10-svhn_0.0:  35%|███▌      | 14/40 [00:01<00:01, 13.59it/s]cifar10-svhn_0.0:  45%|████▌     | 18/40 [00:02<00:01, 17.31it/s]cifar10-svhn_0.0:  52%|█████▎    | 21/40 [00:02<00:01, 18.46it/s]cifar10-svhn_0.0:  60%|██████    | 24/40 [00:02<00:00, 19.43it/s]cifar10-svhn_0.0:  68%|██████▊   | 27/40 [00:02<00:00, 20.28it/s]cifar10-svhn_0.0:  75%|███████▌  | 30/40 [00:02<00:00, 20.91it/s]cifar10-svhn_0.0:  82%|████████▎ | 33/40 [00:02<00:00, 21.05it/s]cifar10-svhn_0.0:  90%|█████████ | 36/40 [00:02<00:00, 22.05it/s]cifar10-svhn_0.0:  98%|█████████▊| 39/40 [00:02<00:00, 22.32it/s]cifar10-svhn_0.0: 100%|██████████| 40/40 [00:03<00:00, 13.00it/s]
cifar10-svhn_0.031:   0%|          | 0/40 [00:00<?, ?it/s]cifar10-svhn_0.031:   2%|▎         | 1/40 [00:10<07:07, 10.97s/it]cifar10-svhn_0.031:   5%|▌         | 2/40 [00:20<06:26, 10.17s/it]cifar10-svhn_0.031:   8%|▊         | 3/40 [00:30<06:06,  9.91s/it]cifar10-svhn_0.031:  10%|█         | 4/40 [00:39<05:52,  9.80s/it]cifar10-svhn_0.031:  12%|█▎        | 5/40 [00:49<05:40,  9.73s/it]cifar10-svhn_0.031:  15%|█▌        | 6/40 [00:59<05:29,  9.70s/it]cifar10-svhn_0.031:  18%|█▊        | 7/40 [01:08<05:19,  9.67s/it]cifar10-svhn_0.031:  20%|██        | 8/40 [01:18<05:09,  9.66s/it]cifar10-svhn_0.031:  22%|██▎       | 9/40 [01:27<04:59,  9.65s/it]cifar10-svhn_0.031:  25%|██▌       | 10/40 [01:37<04:49,  9.65s/it]cifar10-svhn_0.031:  28%|██▊       | 11/40 [01:47<04:39,  9.64s/it]cifar10-svhn_0.031:  30%|███       | 12/40 [01:56<04:29,  9.64s/it]cifar10-svhn_0.031:  32%|███▎      | 13/40 [02:06<04:20,  9.64s/it]cifar10-svhn_0.031:  35%|███▌      | 14/40 [02:16<04:10,  9.64s/it]cifar10-svhn_0.031:  38%|███▊      | 15/40 [02:25<04:01,  9.64s/it]cifar10-svhn_0.031:  40%|████      | 16/40 [02:35<03:51,  9.64s/it]cifar10-svhn_0.031:  42%|████▎     | 17/40 [02:45<03:41,  9.64s/it]cifar10-svhn_0.031:  45%|████▌     | 18/40 [02:54<03:32,  9.64s/it]cifar10-svhn_0.031:  48%|████▊     | 19/40 [03:04<03:22,  9.64s/it]cifar10-svhn_0.031:  50%|█████     | 20/40 [03:14<03:12,  9.65s/it]cifar10-svhn_0.031:  52%|█████▎    | 21/40 [03:23<03:03,  9.65s/it]cifar10-svhn_0.031:  55%|█████▌    | 22/40 [03:33<02:53,  9.65s/it]cifar10-svhn_0.031:  57%|█████▊    | 23/40 [03:42<02:43,  9.65s/it]cifar10-svhn_0.031:  60%|██████    | 24/40 [03:52<02:34,  9.65s/it]cifar10-svhn_0.031:  62%|██████▎   | 25/40 [04:02<02:24,  9.65s/it]cifar10-svhn_0.031:  65%|██████▌   | 26/40 [04:11<02:15,  9.64s/it]cifar10-svhn_0.031:  68%|██████▊   | 27/40 [04:21<02:05,  9.64s/it]cifar10-svhn_0.031:  70%|███████   | 28/40 [04:31<01:55,  9.64s/it]cifar10-svhn_0.031:  72%|███████▎  | 29/40 [04:40<01:46,  9.64s/it]cifar10-svhn_0.031:  75%|███████▌  | 30/40 [04:50<01:36,  9.64s/it]cifar10-svhn_0.031:  78%|███████▊  | 31/40 [05:00<01:26,  9.64s/it]cifar10-svhn_0.031:  80%|████████  | 32/40 [05:09<01:17,  9.65s/it]cifar10-svhn_0.031:  82%|████████▎ | 33/40 [05:19<01:07,  9.65s/it]cifar10-svhn_0.031:  85%|████████▌ | 34/40 [05:29<00:57,  9.64s/it]cifar10-svhn_0.031:  88%|████████▊ | 35/40 [05:38<00:48,  9.64s/it]cifar10-svhn_0.031:  90%|█████████ | 36/40 [05:48<00:38,  9.64s/it]cifar10-svhn_0.031:  92%|█████████▎| 37/40 [05:57<00:28,  9.64s/it]cifar10-svhn_0.031:  95%|█████████▌| 38/40 [06:07<00:19,  9.64s/it]cifar10-svhn_0.031:  98%|█████████▊| 39/40 [06:17<00:09,  9.63s/it]cifar10-svhn_0.031: 100%|██████████| 40/40 [06:18<00:00,  7.09s/it]cifar10-svhn_0.031: 100%|██████████| 40/40 [06:18<00:00,  9.46s/it]
cifar10-svhn_0.0:   0%|          | 0/102 [00:00<?, ?it/s]cifar10-svhn_0.0:   1%|          | 1/102 [00:00<01:34,  1.06it/s]cifar10-svhn_0.0:   4%|▍         | 4/102 [00:01<00:20,  4.70it/s]cifar10-svhn_0.0:   7%|▋         | 7/102 [00:01<00:11,  8.40it/s]cifar10-svhn_0.0:  10%|▉         | 10/102 [00:01<00:08, 11.11it/s]cifar10-svhn_0.0:  12%|█▏        | 12/102 [00:01<00:07, 12.68it/s]cifar10-svhn_0.0:  14%|█▎        | 14/102 [00:01<00:06, 14.19it/s]cifar10-svhn_0.0:  16%|█▌        | 16/102 [00:01<00:05, 15.50it/s]cifar10-svhn_0.0:  18%|█▊        | 18/102 [00:01<00:05, 16.44it/s]cifar10-svhn_0.0:  20%|█▉        | 20/102 [00:01<00:04, 17.28it/s]cifar10-svhn_0.0:  22%|██▏       | 22/102 [00:01<00:04, 17.90it/s]cifar10-svhn_0.0:  24%|██▎       | 24/102 [00:02<00:04, 18.32it/s]cifar10-svhn_0.0:  25%|██▌       | 26/102 [00:02<00:04, 18.16it/s]cifar10-svhn_0.0:  27%|██▋       | 28/102 [00:02<00:03, 18.62it/s]cifar10-svhn_0.0:  29%|██▉       | 30/102 [00:02<00:03, 19.00it/s]cifar10-svhn_0.0:  32%|███▏      | 33/102 [00:02<00:03, 19.61it/s]cifar10-svhn_0.0:  34%|███▍      | 35/102 [00:02<00:03, 19.57it/s]cifar10-svhn_0.0:  36%|███▋      | 37/102 [00:02<00:03, 19.59it/s]cifar10-svhn_0.0:  38%|███▊      | 39/102 [00:02<00:03, 19.40it/s]cifar10-svhn_0.0:  41%|████      | 42/102 [00:02<00:03, 19.33it/s]cifar10-svhn_0.0:  43%|████▎     | 44/102 [00:03<00:03, 19.32it/s]cifar10-svhn_0.0:  45%|████▌     | 46/102 [00:03<00:02, 18.95it/s]cifar10-svhn_0.0:  48%|████▊     | 49/102 [00:03<00:02, 19.79it/s]cifar10-svhn_0.0:  50%|█████     | 51/102 [00:03<00:02, 18.87it/s]cifar10-svhn_0.0:  53%|█████▎    | 54/102 [00:03<00:02, 18.86it/s]cifar10-svhn_0.0:  56%|█████▌    | 57/102 [00:03<00:02, 19.66it/s]cifar10-svhn_0.0:  59%|█████▉    | 60/102 [00:03<00:02, 19.48it/s]cifar10-svhn_0.0:  61%|██████    | 62/102 [00:04<00:02, 19.50it/s]cifar10-svhn_0.0:  64%|██████▎   | 65/102 [00:04<00:01, 20.09it/s]cifar10-svhn_0.0:  67%|██████▋   | 68/102 [00:04<00:01, 19.23it/s]cifar10-svhn_0.0:  70%|██████▉   | 71/102 [00:04<00:01, 20.12it/s]cifar10-svhn_0.0:  73%|███████▎  | 74/102 [00:04<00:01, 19.63it/s]cifar10-svhn_0.0:  75%|███████▍  | 76/102 [00:04<00:01, 19.67it/s]cifar10-svhn_0.0:  76%|███████▋  | 78/102 [00:04<00:01, 19.61it/s]cifar10-svhn_0.0:  78%|███████▊  | 80/102 [00:04<00:01, 19.54it/s]cifar10-svhn_0.0:  81%|████████▏ | 83/102 [00:05<00:00, 20.21it/s]cifar10-svhn_0.0:  84%|████████▍ | 86/102 [00:05<00:00, 19.23it/s]cifar10-svhn_0.0:  87%|████████▋ | 89/102 [00:05<00:00, 20.44it/s]cifar10-svhn_0.0:  90%|█████████ | 92/102 [00:05<00:00, 19.07it/s]cifar10-svhn_0.0:  93%|█████████▎| 95/102 [00:05<00:00, 20.44it/s]cifar10-svhn_0.0:  96%|█████████▌| 98/102 [00:05<00:00, 19.32it/s]cifar10-svhn_0.0:  98%|█████████▊| 100/102 [00:05<00:00, 19.24it/s]cifar10-svhn_0.0: 100%|██████████| 102/102 [00:06<00:00, 14.74it/s]cifar10-svhn_0.0: 100%|██████████| 102/102 [00:06<00:00, 16.31it/s]
cifar10-svhn_0.031:   0%|          | 0/102 [00:00<?, ?it/s]cifar10-svhn_0.031:   1%|          | 1/102 [00:10<17:42, 10.52s/it]cifar10-svhn_0.031:   2%|▏         | 2/102 [00:20<16:40, 10.00s/it]cifar10-svhn_0.031:   3%|▎         | 3/102 [00:29<16:14,  9.84s/it]cifar10-svhn_0.031:   4%|▍         | 4/102 [00:39<15:56,  9.77s/it]cifar10-svhn_0.031:   5%|▍         | 5/102 [00:49<15:42,  9.72s/it]cifar10-svhn_0.031:   6%|▌         | 6/102 [00:58<15:30,  9.69s/it]cifar10-svhn_0.031:   7%|▋         | 7/102 [01:08<15:19,  9.67s/it]cifar10-svhn_0.031:   8%|▊         | 8/102 [01:18<15:08,  9.67s/it]cifar10-svhn_0.031:   9%|▉         | 9/102 [01:27<14:58,  9.66s/it]cifar10-svhn_0.031:  10%|▉         | 10/102 [01:37<14:48,  9.66s/it]cifar10-svhn_0.031:  11%|█         | 11/102 [01:46<14:38,  9.65s/it]cifar10-svhn_0.031:  12%|█▏        | 12/102 [01:56<14:28,  9.65s/it]cifar10-svhn_0.031:  13%|█▎        | 13/102 [02:06<14:18,  9.65s/it]cifar10-svhn_0.031:  14%|█▎        | 14/102 [02:15<14:08,  9.65s/it]cifar10-svhn_0.031:  15%|█▍        | 15/102 [02:25<13:59,  9.65s/it]cifar10-svhn_0.031:  16%|█▌        | 16/102 [02:35<13:49,  9.65s/it]cifar10-svhn_0.031:  17%|█▋        | 17/102 [02:44<13:39,  9.65s/it]cifar10-svhn_0.031:  18%|█▊        | 18/102 [02:54<13:30,  9.65s/it]cifar10-svhn_0.031:  19%|█▊        | 19/102 [03:04<13:20,  9.65s/it]cifar10-svhn_0.031:  20%|█▉        | 20/102 [03:13<13:11,  9.65s/it]cifar10-svhn_0.031:  21%|██        | 21/102 [03:23<13:01,  9.65s/it]cifar10-svhn_0.031:  22%|██▏       | 22/102 [03:33<12:51,  9.65s/it]cifar10-svhn_0.031:  23%|██▎       | 23/102 [03:42<12:42,  9.65s/it]cifar10-svhn_0.031:  24%|██▎       | 24/102 [03:52<12:32,  9.65s/it]cifar10-svhn_0.031:  25%|██▍       | 25/102 [04:01<12:22,  9.64s/it]cifar10-svhn_0.031:  25%|██▌       | 26/102 [04:11<12:12,  9.64s/it]cifar10-svhn_0.031:  26%|██▋       | 27/102 [04:21<12:03,  9.64s/it]cifar10-svhn_0.031:  27%|██▋       | 28/102 [04:30<11:53,  9.64s/it]cifar10-svhn_0.031:  28%|██▊       | 29/102 [04:40<11:43,  9.64s/it]cifar10-svhn_0.031:  29%|██▉       | 30/102 [04:50<11:34,  9.64s/it]cifar10-svhn_0.031:  30%|███       | 31/102 [04:59<11:24,  9.64s/it]cifar10-svhn_0.031:  31%|███▏      | 32/102 [05:09<11:15,  9.64s/it]cifar10-svhn_0.031:  32%|███▏      | 33/102 [05:19<11:05,  9.65s/it]cifar10-svhn_0.031:  33%|███▎      | 34/102 [05:28<10:55,  9.65s/it]cifar10-svhn_0.031:  34%|███▍      | 35/102 [05:38<10:46,  9.65s/it]cifar10-svhn_0.031:  35%|███▌      | 36/102 [05:48<10:36,  9.64s/it]cifar10-svhn_0.031:  36%|███▋      | 37/102 [05:57<10:26,  9.64s/it]cifar10-svhn_0.031:  37%|███▋      | 38/102 [06:07<10:17,  9.64s/it]cifar10-svhn_0.031:  38%|███▊      | 39/102 [06:17<10:07,  9.64s/it]cifar10-svhn_0.031:  39%|███▉      | 40/102 [06:26<09:57,  9.64s/it]cifar10-svhn_0.031:  40%|████      | 41/102 [06:36<09:48,  9.64s/it]cifar10-svhn_0.031:  41%|████      | 42/102 [06:45<09:38,  9.64s/it]cifar10-svhn_0.031:  42%|████▏     | 43/102 [06:55<09:28,  9.64s/it]cifar10-svhn_0.031:  43%|████▎     | 44/102 [07:05<09:19,  9.64s/it]cifar10-svhn_0.031:  44%|████▍     | 45/102 [07:14<09:09,  9.64s/it]cifar10-svhn_0.031:  45%|████▌     | 46/102 [07:24<08:59,  9.64s/it]cifar10-svhn_0.031:  46%|████▌     | 47/102 [07:34<08:50,  9.64s/it]cifar10-svhn_0.031:  47%|████▋     | 48/102 [07:43<08:40,  9.64s/it]cifar10-svhn_0.031:  48%|████▊     | 49/102 [07:53<08:30,  9.64s/it]cifar10-svhn_0.031:  49%|████▉     | 50/102 [08:03<08:21,  9.64s/it]cifar10-svhn_0.031:  50%|█████     | 51/102 [08:12<08:11,  9.64s/it]cifar10-svhn_0.031:  51%|█████     | 52/102 [08:22<08:02,  9.64s/it]cifar10-svhn_0.031:  52%|█████▏    | 53/102 [08:32<07:52,  9.64s/it]cifar10-svhn_0.031:  53%|█████▎    | 54/102 [08:41<07:42,  9.64s/it]cifar10-svhn_0.031:  54%|█████▍    | 55/102 [08:51<07:33,  9.64s/it]cifar10-svhn_0.031:  55%|█████▍    | 56/102 [09:00<07:23,  9.64s/it]cifar10-svhn_0.031:  56%|█████▌    | 57/102 [09:10<07:13,  9.64s/it]cifar10-svhn_0.031:  57%|█████▋    | 58/102 [09:20<07:04,  9.65s/it]cifar10-svhn_0.031:  58%|█████▊    | 59/102 [09:29<06:54,  9.64s/it]cifar10-svhn_0.031:  59%|█████▉    | 60/102 [09:39<06:45,  9.64s/it]cifar10-svhn_0.031:  60%|█████▉    | 61/102 [09:49<06:35,  9.64s/it]cifar10-svhn_0.031:  61%|██████    | 62/102 [09:58<06:25,  9.64s/it]cifar10-svhn_0.031:  62%|██████▏   | 63/102 [10:08<06:15,  9.64s/it]cifar10-svhn_0.031:  63%|██████▎   | 64/102 [10:18<06:06,  9.64s/it]cifar10-svhn_0.031:  64%|██████▎   | 65/102 [10:27<05:56,  9.64s/it]cifar10-svhn_0.031:  65%|██████▍   | 66/102 [10:37<05:47,  9.64s/it]cifar10-svhn_0.031:  66%|██████▌   | 67/102 [10:46<05:37,  9.64s/it]cifar10-svhn_0.031:  67%|██████▋   | 68/102 [10:56<05:27,  9.64s/it]cifar10-svhn_0.031:  68%|██████▊   | 69/102 [11:06<05:18,  9.64s/it]cifar10-svhn_0.031:  69%|██████▊   | 70/102 [11:15<05:08,  9.64s/it]cifar10-svhn_0.031:  70%|██████▉   | 71/102 [11:25<04:58,  9.64s/it]cifar10-svhn_0.031:  71%|███████   | 72/102 [11:35<04:49,  9.65s/it]cifar10-svhn_0.031:  72%|███████▏  | 73/102 [11:44<04:39,  9.64s/it]cifar10-svhn_0.031:  73%|███████▎  | 74/102 [11:54<04:30,  9.65s/it]cifar10-svhn_0.031:  74%|███████▎  | 75/102 [12:04<04:20,  9.64s/it]cifar10-svhn_0.031:  75%|███████▍  | 76/102 [12:13<04:10,  9.65s/it]cifar10-svhn_0.031:  75%|███████▌  | 77/102 [12:23<04:01,  9.64s/it]cifar10-svhn_0.031:  76%|███████▋  | 78/102 [12:33<03:51,  9.64s/it]cifar10-svhn_0.031:  77%|███████▋  | 79/102 [12:42<03:41,  9.64s/it]cifar10-svhn_0.031:  78%|███████▊  | 80/102 [12:52<03:32,  9.64s/it]cifar10-svhn_0.031:  79%|███████▉  | 81/102 [13:02<03:22,  9.64s/it]cifar10-svhn_0.031:  80%|████████  | 82/102 [13:11<03:12,  9.64s/it]cifar10-svhn_0.031:  81%|████████▏ | 83/102 [13:21<03:03,  9.64s/it]cifar10-svhn_0.031:  82%|████████▏ | 84/102 [13:30<02:53,  9.64s/it]cifar10-svhn_0.031:  83%|████████▎ | 85/102 [13:40<02:43,  9.64s/it]cifar10-svhn_0.031:  84%|████████▍ | 86/102 [13:50<02:34,  9.64s/it]cifar10-svhn_0.031:  85%|████████▌ | 87/102 [13:59<02:24,  9.64s/it]cifar10-svhn_0.031:  86%|████████▋ | 88/102 [14:09<02:14,  9.64s/it]cifar10-svhn_0.031:  87%|████████▋ | 89/102 [14:19<02:05,  9.64s/it]cifar10-svhn_0.031:  88%|████████▊ | 90/102 [14:28<01:55,  9.64s/it]cifar10-svhn_0.031:  89%|████████▉ | 91/102 [14:38<01:46,  9.64s/it]cifar10-svhn_0.031:  90%|█████████ | 92/102 [14:48<01:36,  9.64s/it]cifar10-svhn_0.031:  91%|█████████ | 93/102 [14:57<01:26,  9.64s/it]cifar10-svhn_0.031:  92%|█████████▏| 94/102 [15:07<01:17,  9.64s/it]cifar10-svhn_0.031:  93%|█████████▎| 95/102 [15:16<01:07,  9.64s/it]cifar10-svhn_0.031:  94%|█████████▍| 96/102 [15:26<00:57,  9.64s/it]cifar10-svhn_0.031:  95%|█████████▌| 97/102 [15:36<00:48,  9.64s/it]cifar10-svhn_0.031:  96%|█████████▌| 98/102 [15:45<00:38,  9.64s/it]cifar10-svhn_0.031:  97%|█████████▋| 99/102 [15:55<00:28,  9.63s/it]cifar10-svhn_0.031:  98%|█████████▊| 100/102 [16:05<00:19,  9.63s/it]cifar10-svhn_0.031:  99%|█████████▉| 101/102 [16:14<00:09,  9.63s/it]cifar10-svhn_0.031: 100%|██████████| 102/102 [16:21<00:00,  8.90s/it]cifar10-svhn_0.031: 100%|██████████| 102/102 [16:22<00:00,  9.63s/it]

dataset: cifar10-svhn

just in attacked
eps= 0.0 : 0.8873851317609096
TPR at 0.95 TNR 0.6599569760295021
eps= 0.0313 : 0.700624085740627

just out attacked
eps= 0.0 : 0.8873851317609096
eps= 0.0313 : 0.6078401621081746

both attacked
eps= 0.0 : 0.8873851317609096
eps= 0.0313 : 0.3671696469729564
